{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab787c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\anaconda\\envs\\meowscanenv\\lib\\site-packages (2.10.0)\n",
      "Requirement already satisfied: torchvision in c:\\anaconda\\envs\\meowscanenv\\lib\\site-packages (0.25.0)\n",
      "Requirement already satisfied: opencv-python in c:\\anaconda\\envs\\meowscanenv\\lib\\site-packages (4.13.0.90)\n",
      "Requirement already satisfied: transformers in c:\\anaconda\\envs\\meowscanenv\\lib\\site-packages (5.0.0)\n",
      "Requirement already satisfied: timm in c:\\anaconda\\envs\\meowscanenv\\lib\\site-packages (1.0.24)\n",
      "Requirement already satisfied: effdet in c:\\anaconda\\envs\\meowscanenv\\lib\\site-packages (0.4.1)\n",
      "Requirement already satisfied: pillow in c:\\anaconda\\envs\\meowscanenv\\lib\\site-packages (12.1.0)\n",
      "Requirement already satisfied: filelock in c:\\anaconda\\envs\\meowscanenv\\lib\\site-packages (from torch) (3.20.3)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\anaconda\\envs\\meowscanenv\\lib\\site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\anaconda\\envs\\meowscanenv\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\anaconda\\envs\\meowscanenv\\lib\\site-packages (from torch) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in c:\\anaconda\\envs\\meowscanenv\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in c:\\anaconda\\envs\\meowscanenv\\lib\\site-packages (from torch) (2026.1.0)\n",
      "Requirement already satisfied: setuptools in c:\\anaconda\\envs\\meowscanenv\\lib\\site-packages (from torch) (80.10.2)\n",
      "Requirement already satisfied: numpy in c:\\anaconda\\envs\\meowscanenv\\lib\\site-packages (from torchvision) (2.4.2)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=1.3.0 in c:\\anaconda\\envs\\meowscanenv\\lib\\site-packages (from transformers) (1.4.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\anaconda\\envs\\meowscanenv\\lib\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\anaconda\\envs\\meowscanenv\\lib\\site-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\anaconda\\envs\\meowscanenv\\lib\\site-packages (from transformers) (2026.1.15)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\anaconda\\envs\\meowscanenv\\lib\\site-packages (from transformers) (0.22.2)\n",
      "Requirement already satisfied: typer-slim in c:\\anaconda\\envs\\meowscanenv\\lib\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\anaconda\\envs\\meowscanenv\\lib\\site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\anaconda\\envs\\meowscanenv\\lib\\site-packages (from transformers) (4.67.3)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in c:\\anaconda\\envs\\meowscanenv\\lib\\site-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (1.2.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\anaconda\\envs\\meowscanenv\\lib\\site-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (0.28.1)\n",
      "Requirement already satisfied: shellingham in c:\\anaconda\\envs\\meowscanenv\\lib\\site-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (1.5.4)\n",
      "Requirement already satisfied: anyio in c:\\anaconda\\envs\\meowscanenv\\lib\\site-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (4.12.1)\n",
      "Requirement already satisfied: certifi in c:\\anaconda\\envs\\meowscanenv\\lib\\site-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\anaconda\\envs\\meowscanenv\\lib\\site-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\anaconda\\envs\\meowscanenv\\lib\\site-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\anaconda\\envs\\meowscanenv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (0.16.0)\n",
      "Requirement already satisfied: pycocotools>=2.0.2 in c:\\anaconda\\envs\\meowscanenv\\lib\\site-packages (from effdet) (2.0.11)\n",
      "Requirement already satisfied: omegaconf>=2.0 in c:\\anaconda\\envs\\meowscanenv\\lib\\site-packages (from effdet) (2.3.0)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in c:\\anaconda\\envs\\meowscanenv\\lib\\site-packages (from omegaconf>=2.0->effdet) (4.9.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\anaconda\\envs\\meowscanenv\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\anaconda\\envs\\meowscanenv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\anaconda\\envs\\meowscanenv\\lib\\site-packages (from jinja2->torch) (3.0.3)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\anaconda\\envs\\meowscanenv\\lib\\site-packages (from typer-slim->transformers) (8.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision opencv-python transformers timm effdet pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1798f57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from transformers import ViTImageProcessor, ViTForImageClassification\n",
    "from effdet import get_efficientdet_config, EfficientDet, DetBenchPredict\n",
    "from timm.data import create_transform\n",
    "from omegaconf import OmegaConf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a03a0739",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CatAnalysisSystem:\n",
    "    def __init__(self, device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "        self.device = device\n",
    "        print(f\"Using device: {self.device}\")\n",
    "        \n",
    "        # --- STAGE 1: LOAD EFFICIENTDET (Object Detection) ---\n",
    "        print(\"Loading EfficientDet...\")\n",
    "        # ใช้ tf_efficientdet_d0 (รุ่นเล็กสุดแต่เร็ว) หรือเปลี่ยนเป็น d1-d7 ถ้าต้องการแม่นขึ้น\n",
    "        self.det_config = get_efficientdet_config('tf_efficientdet_d0')\n",
    "        self.det_net = EfficientDet(self.det_config, pretrained_backbone=False)\n",
    "        checkpoint = torch.hub.load_state_dict_from_url(\n",
    "            \"https://github.com/rwightman/efficientdet-pytorch/releases/download/v0.1/tf_efficientdet_d0_34-f153e0cf.pth\", \n",
    "            map_location=device\n",
    "        )\n",
    "        self.det_net.load_state_dict(checkpoint)\n",
    "        # 1. ปลดล็อค Config ให้แก้ไขได้\n",
    "        OmegaConf.set_readonly(self.det_config, False) \n",
    "\n",
    "        # 2. ตอนนี้จะแก้ไขค่าได้แล้ว ไม่ error\n",
    "        self.det_config.num_classes = 90     \n",
    "        self.det_config.image_size = [512, 512]\n",
    "        self.det_model = DetBenchPredict(self.det_net)\n",
    "        self.det_model.eval().to(self.device)\n",
    "\n",
    "        # --- STAGE 2: LOAD VISION TRANSFORMER (Classification) ---\n",
    "        print(\"Loading Vision Transformer (ViT)...\")\n",
    "        # ใช้ Pre-trained ImageNet (มีแมวหลายสายพันธุ์)\n",
    "        self.vit_model_name = 'google/vit-base-patch16-224' \n",
    "        self.vit_processor = ViTImageProcessor.from_pretrained(self.vit_model_name)\n",
    "        self.vit_model = ViTForImageClassification.from_pretrained(self.vit_model_name)\n",
    "        self.vit_model.eval().to(self.device)\n",
    "\n",
    "    def detect_cats(self, img_cv2, threshold=0.5):\n",
    "        \"\"\"Stage 1: Detect objects and filter only Cats\"\"\"\n",
    "        # เตรียมภาพสำหรับ EfficientDet\n",
    "        img_rgb = cv2.cvtColor(img_cv2, cv2.COLOR_BGR2RGB)\n",
    "        src_img = Image.fromarray(img_rgb)\n",
    "        \n",
    "        # Transform (Resize/Normalize) ตาม config ของ EfficientDet\n",
    "        transform = create_transform(\n",
    "            self.det_config.image_size, \n",
    "            mean=self.det_config.mean, \n",
    "            std=self.det_config.std\n",
    "        )\n",
    "        img_tensor = transform(src_img).unsqueeze(0).to(self.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = self.det_model(img_tensor)\n",
    "\n",
    "        # Output format: [batch, max_det, 6] -> (x_min, y_min, x_max, y_max, score, class)\n",
    "        results = output.cpu().numpy()[0]\n",
    "\n",
    "        cat_boxes = []\n",
    "        # COCO Dataset: Class ID 17 คือ Cat (ใน effdet index อาจจะเริ่มที่ 1 คือ Person, ดังนั้น Cat ~17)\n",
    "        # หมายเหตุ: EfficientDet Pretrained ส่วนใหญ่ map COCO 90 classes. Cat ID มักจะเป็น 17.\n",
    "        CAT_CLASS_ID = 17 \n",
    "        \n",
    "        for res in results:\n",
    "            xmin, ymin, xmax, ymax, score, class_id = res\n",
    "            if score > threshold and int(class_id) == CAT_CLASS_ID:\n",
    "                # แปลงพิกัดกลับไปเป็นขนาดภาพจริง (เนื่องจาก input ถูก resize)\n",
    "                h_orig, w_orig = img_cv2.shape[:2]\n",
    "                h_model, w_model = self.det_config.image_size\n",
    "                \n",
    "                scale_x = w_orig / w_model\n",
    "                scale_y = h_orig / h_model\n",
    "                \n",
    "                # ถ้า transform มีการ pad ต้องคำนวณละเอียดกว่านี้ แต่นี่คือแบบคร่าวๆ\n",
    "                # เพื่อความแม่นยำสูงสุดควรใช้ transform ย้อนกลับ แต่เพื่อความง่ายใช้ ratio\n",
    "                \n",
    "                cat_boxes.append([\n",
    "                    int(xmin * scale_x), int(ymin * scale_y), \n",
    "                    int(xmax * scale_x), int(ymax * scale_y), \n",
    "                    score\n",
    "                ])\n",
    "                \n",
    "        return cat_boxes\n",
    "\n",
    "    def classify_breed(self, crop_img_cv2):\n",
    "        \"\"\"Stage 2: Classify breed using ViT\"\"\"\n",
    "        if crop_img_cv2.size == 0: return \"Unknown\", 0.0\n",
    "        \n",
    "        img_rgb = cv2.cvtColor(crop_img_cv2, cv2.COLOR_BGR2RGB)\n",
    "        inputs = self.vit_processor(images=img_rgb, return_tensors=\"pt\").to(self.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = self.vit_model(**inputs)\n",
    "            logits = outputs.logits\n",
    "            probs = logits.softmax(dim=1)\n",
    "            top_prob, top_idx = probs.max(1)\n",
    "        \n",
    "        # ดึงชื่อ Label จาก ViT config\n",
    "        breed_name = self.vit_model.config.id2label[top_idx.item()]\n",
    "        # ตัดคำให้สั้นลง (เช่น \"tabby, tabby cat\" -> \"tabby\")\n",
    "        breed_name = breed_name.split(',')[0] \n",
    "        \n",
    "        return breed_name, top_prob.item()\n",
    "\n",
    "    def run(self, image_path):\n",
    "        img = cv2.imread(image_path)\n",
    "        if img is None:\n",
    "            print(\"Image not found\")\n",
    "            return\n",
    "\n",
    "        # 1. Detection\n",
    "        boxes = self.detect_cats(img)\n",
    "        print(f\"Found {len(boxes)} cats.\")\n",
    "\n",
    "        for box in boxes:\n",
    "            xmin, ymin, xmax, ymax, score = box\n",
    "            \n",
    "            # กัน Error กรณีพิกัดออกนอกภาพ\n",
    "            xmin, ymin = max(0, xmin), max(0, ymin)\n",
    "            xmax, ymax = min(img.shape[1], xmax), min(img.shape[0], ymax)\n",
    "\n",
    "            # 2. Crop Image\n",
    "            cat_crop = img[ymin:ymax, xmin:xmax]\n",
    "            \n",
    "            # 3. Classification\n",
    "            breed, conf = self.classify_breed(cat_crop)\n",
    "            print(f\"Cat at [{xmin},{ymin}] is likely: {breed} ({conf:.2f})\")\n",
    "\n",
    "            # Draw\n",
    "            cv2.rectangle(img, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)\n",
    "            label = f\"{breed}: {conf:.2f}\"\n",
    "            cv2.putText(img, label, (xmin, ymin - 10), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "\n",
    "        # Show result\n",
    "        cv2.imshow(\"Two-Stage Cat Analysis\", img)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f9782f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Loading EfficientDet...\n",
      "Loading Vision Transformer (ViT)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\anaconda\\envs\\meowscanenv\\Lib\\site-packages\\huggingface_hub\\file_download.py:130: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Advice IT\\.cache\\huggingface\\hub\\models--google--vit-base-patch16-224. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
      "WARNING:huggingface_hub.utils._http:Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
     ]
    }
   ],
   "source": [
    "# --- วิธีใช้งาน ---\n",
    "if __name__ == \"__main__\":\n",
    "    # ใส่ path รูปแมวของคุณที่นี่\n",
    "    image_path = \"C:/Users/Advice IT/MeowScannerWeb/cat.jpeg\" \n",
    "    \n",
    "    system = CatAnalysisSystem()\n",
    "    system.run(image_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meowscanenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
