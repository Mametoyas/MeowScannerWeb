{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab787c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\anaconda\\envs\\meowscanenv\\lib\\site-packages (2.10.0)\n",
      "Requirement already satisfied: torchvision in c:\\anaconda\\envs\\meowscanenv\\lib\\site-packages (0.25.0)\n",
      "Requirement already satisfied: opencv-python in c:\\anaconda\\envs\\meowscanenv\\lib\\site-packages (4.13.0.90)\n",
      "Requirement already satisfied: transformers in c:\\anaconda\\envs\\meowscanenv\\lib\\site-packages (5.0.0)\n",
      "Requirement already satisfied: timm in c:\\anaconda\\envs\\meowscanenv\\lib\\site-packages (1.0.24)\n",
      "Requirement already satisfied: effdet in c:\\anaconda\\envs\\meowscanenv\\lib\\site-packages (0.4.1)\n",
      "Requirement already satisfied: pillow in c:\\anaconda\\envs\\meowscanenv\\lib\\site-packages (12.1.0)\n",
      "Requirement already satisfied: filelock in c:\\anaconda\\envs\\meowscanenv\\lib\\site-packages (from torch) (3.20.3)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\anaconda\\envs\\meowscanenv\\lib\\site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\anaconda\\envs\\meowscanenv\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\anaconda\\envs\\meowscanenv\\lib\\site-packages (from torch) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in c:\\anaconda\\envs\\meowscanenv\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in c:\\anaconda\\envs\\meowscanenv\\lib\\site-packages (from torch) (2026.1.0)\n",
      "Requirement already satisfied: setuptools in c:\\anaconda\\envs\\meowscanenv\\lib\\site-packages (from torch) (80.10.2)\n",
      "Requirement already satisfied: numpy in c:\\anaconda\\envs\\meowscanenv\\lib\\site-packages (from torchvision) (2.4.2)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=1.3.0 in c:\\anaconda\\envs\\meowscanenv\\lib\\site-packages (from transformers) (1.4.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\anaconda\\envs\\meowscanenv\\lib\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\anaconda\\envs\\meowscanenv\\lib\\site-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\anaconda\\envs\\meowscanenv\\lib\\site-packages (from transformers) (2026.1.15)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\anaconda\\envs\\meowscanenv\\lib\\site-packages (from transformers) (0.22.2)\n",
      "Requirement already satisfied: typer-slim in c:\\anaconda\\envs\\meowscanenv\\lib\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\anaconda\\envs\\meowscanenv\\lib\\site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\anaconda\\envs\\meowscanenv\\lib\\site-packages (from transformers) (4.67.3)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in c:\\anaconda\\envs\\meowscanenv\\lib\\site-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (1.2.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\anaconda\\envs\\meowscanenv\\lib\\site-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (0.28.1)\n",
      "Requirement already satisfied: shellingham in c:\\anaconda\\envs\\meowscanenv\\lib\\site-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (1.5.4)\n",
      "Requirement already satisfied: anyio in c:\\anaconda\\envs\\meowscanenv\\lib\\site-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (4.12.1)\n",
      "Requirement already satisfied: certifi in c:\\anaconda\\envs\\meowscanenv\\lib\\site-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\anaconda\\envs\\meowscanenv\\lib\\site-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\anaconda\\envs\\meowscanenv\\lib\\site-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\anaconda\\envs\\meowscanenv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (0.16.0)\n",
      "Requirement already satisfied: pycocotools>=2.0.2 in c:\\anaconda\\envs\\meowscanenv\\lib\\site-packages (from effdet) (2.0.11)\n",
      "Requirement already satisfied: omegaconf>=2.0 in c:\\anaconda\\envs\\meowscanenv\\lib\\site-packages (from effdet) (2.3.0)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in c:\\anaconda\\envs\\meowscanenv\\lib\\site-packages (from omegaconf>=2.0->effdet) (4.9.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\anaconda\\envs\\meowscanenv\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\anaconda\\envs\\meowscanenv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\anaconda\\envs\\meowscanenv\\lib\\site-packages (from jinja2->torch) (3.0.3)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\anaconda\\envs\\meowscanenv\\lib\\site-packages (from typer-slim->transformers) (8.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision opencv-python transformers timm effdet pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1798f57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# --- IMPORTS FOR DETECTION ---\n",
    "from effdet import get_efficientdet_config, EfficientDet, DetBenchPredict\n",
    "# แก้ไข 1: Import create_transform จาก timm.data แทน effdet.data\n",
    "from timm.data import create_transform \n",
    "# แก้ไข 2: Import OmegaConf เพื่อปลดล็อค config\n",
    "from omegaconf import OmegaConf \n",
    "\n",
    "# --- IMPORTS FOR CLASSIFICATION ---\n",
    "from transformers import ViTImageProcessor, ViTForImageClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a03a0739",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CatAnalysisSystem:\n",
    "    def __init__(self, device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "        self.device = device\n",
    "        print(f\"Using device: {self.device}\")\n",
    "        \n",
    "        # --- STAGE 1: LOAD EFFICIENTDET (Object Detection) ---\n",
    "        print(\"Loading EfficientDet...\")\n",
    "        self.det_config = get_efficientdet_config('tf_efficientdet_d0')\n",
    "        self.det_net = EfficientDet(self.det_config, pretrained_backbone=False)\n",
    "        \n",
    "        # Load Pretrained Weights manually\n",
    "        checkpoint = torch.hub.load_state_dict_from_url(\n",
    "            \"https://github.com/rwightman/efficientdet-pytorch/releases/download/v0.1/tf_efficientdet_d0_34-f153e0cf.pth\", \n",
    "            map_location=device\n",
    "        )\n",
    "        self.det_net.load_state_dict(checkpoint)\n",
    "\n",
    "        # แก้ไข 3: ปลดล็อค Config ก่อนแก้ไขค่า\n",
    "        OmegaConf.set_readonly(self.det_config, False) \n",
    "        self.det_config.num_classes = 90     \n",
    "        self.det_config.image_size = [512, 512]\n",
    "\n",
    "        # แก้ไข 4: ส่งแค่ net เข้าไป (ไม่ต้องส่ง config)\n",
    "        self.det_model = DetBenchPredict(self.det_net) \n",
    "        self.det_model.eval().to(self.device)\n",
    "\n",
    "        # --- STAGE 2: LOAD VISION TRANSFORMER (Classification) ---\n",
    "        print(\"Loading Vision Transformer (ViT)...\")\n",
    "        self.vit_model_name = 'google/vit-base-patch16-224' \n",
    "        self.vit_processor = ViTImageProcessor.from_pretrained(self.vit_model_name)\n",
    "        self.vit_model = ViTForImageClassification.from_pretrained(self.vit_model_name)\n",
    "        self.vit_model.eval().to(self.device)\n",
    "\n",
    "    def detect_cats(self, img_cv2, threshold=0.5):\n",
    "            \"\"\"Stage 1: Detect objects and filter only Cats\"\"\"\n",
    "            img_rgb = cv2.cvtColor(img_cv2, cv2.COLOR_BGR2RGB)\n",
    "            src_img = Image.fromarray(img_rgb)\n",
    "            \n",
    "            # --- แก้ไขจุดที่ Error (เพิ่มเลข 3 เข้าไปข้างหน้า) ---\n",
    "            img_h, img_w = self.det_config.image_size[0], self.det_config.image_size[1]\n",
    "            transform = create_transform(\n",
    "                input_size=(3, img_h, img_w),  # ต้องเป็น format (C, H, W)\n",
    "                mean=[0.485, 0.456, 0.406], \n",
    "                std=[0.229, 0.224, 0.225]\n",
    "            )\n",
    "            # ------------------------------------------------\n",
    "            \n",
    "            img_tensor = transform(src_img).unsqueeze(0).to(self.device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                output = self.det_model(img_tensor)\n",
    "\n",
    "            results = output.cpu().numpy()[0]\n",
    "            cat_boxes = []\n",
    "            \n",
    "            # COCO Dataset: Cat ID is usually 17\n",
    "            CAT_CLASS_ID = 17 \n",
    "            \n",
    "            for res in results:\n",
    "                xmin, ymin, xmax, ymax, score, class_id = res\n",
    "                if score > threshold and int(class_id) == CAT_CLASS_ID:\n",
    "                    h_orig, w_orig = img_cv2.shape[:2]\n",
    "                    h_model, w_model = self.det_config.image_size\n",
    "                    \n",
    "                    scale_x = w_orig / w_model\n",
    "                    scale_y = h_orig / h_model\n",
    "                    \n",
    "                    cat_boxes.append([\n",
    "                        int(xmin * scale_x), int(ymin * scale_y), \n",
    "                        int(xmax * scale_x), int(ymax * scale_y), \n",
    "                        score\n",
    "                    ])\n",
    "                    \n",
    "            return cat_boxes\n",
    "\n",
    "    def classify_breed(self, crop_img_cv2):\n",
    "        \"\"\"Stage 2: Classify breed using ViT\"\"\"\n",
    "        if crop_img_cv2.size == 0: return \"Unknown\", 0.0\n",
    "        \n",
    "        img_rgb = cv2.cvtColor(crop_img_cv2, cv2.COLOR_BGR2RGB)\n",
    "        inputs = self.vit_processor(images=img_rgb, return_tensors=\"pt\").to(self.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = self.vit_model(**inputs)\n",
    "            logits = outputs.logits\n",
    "            probs = logits.softmax(dim=1)\n",
    "            top_prob, top_idx = probs.max(1)\n",
    "        \n",
    "        breed_name = self.vit_model.config.id2label[top_idx.item()]\n",
    "        breed_name = breed_name.split(',')[0] \n",
    "        \n",
    "        return breed_name, top_prob.item()\n",
    "\n",
    "    def run(self, image_path):\n",
    "        print(f\"Reading image from: {image_path}\")\n",
    "        img = cv2.imread(image_path)\n",
    "        if img is None:\n",
    "            print(\"Error: Image not found. Please check the path.\")\n",
    "            return\n",
    "\n",
    "        # 1. Detection\n",
    "        boxes = self.detect_cats(img)\n",
    "        print(f\"Found {len(boxes)} cats.\")\n",
    "\n",
    "        for box in boxes:\n",
    "            xmin, ymin, xmax, ymax, score = box\n",
    "            \n",
    "            # Clamp coordinates\n",
    "            xmin, ymin = max(0, xmin), max(0, ymin)\n",
    "            xmax, ymax = min(img.shape[1], xmax), min(img.shape[0], ymax)\n",
    "\n",
    "            # 2. Crop Image\n",
    "            cat_crop = img[ymin:ymax, xmin:xmax]\n",
    "            \n",
    "            # 3. Classification\n",
    "            breed, conf = self.classify_breed(cat_crop)\n",
    "            print(f\"Cat at [{xmin},{ymin}] is likely: {breed} ({conf:.2f})\")\n",
    "\n",
    "            # Draw\n",
    "            cv2.rectangle(img, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)\n",
    "            label = f\"{breed}: {conf:.2f}\"\n",
    "            cv2.putText(img, label, (xmin, ymin - 10), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "\n",
    "        # Show result\n",
    "        cv2.imshow(\"Two-Stage Cat Analysis\", img)\n",
    "        print(\"Press any key on the image window to close...\")\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a0f9782f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Loading EfficientDet...\n",
      "Loading Vision Transformer (ViT)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 200/200 [00:00<00:00, 423.19it/s, Materializing param=vit.layernorm.weight]                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading image from: C:/Users/Advice IT/MeowScannerWeb/image.png\n",
      "Found 2 cats.\n",
      "Cat at [862,64] is likely: tabby (0.63)\n",
      "Cat at [141,87] is likely: tabby (0.53)\n",
      "Press any key on the image window to close...\n"
     ]
    }
   ],
   "source": [
    "# --- วิธีใช้งาน ---\n",
    "if __name__ == \"__main__\":\n",
    "    # ใส่ path รูปแมวของคุณที่นี่\n",
    "    image_path = \"C:/Users/Advice IT/MeowScannerWeb/image.png\" \n",
    "    \n",
    "    system = CatAnalysisSystem()\n",
    "    system.run(image_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meowscanenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
